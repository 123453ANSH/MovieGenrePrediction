{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harshikajalan/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv('archive/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies.filter(['original_title', 'id', 'imdb_id','vote_average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>6.5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>6.1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>5.7</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title     id    imdb_id  vote_average reviews\n",
       "0                    Toy Story    862  tt0114709           7.7      []\n",
       "1                      Jumanji   8844  tt0113497           6.9      []\n",
       "2             Grumpier Old Men  15602  tt0113228           6.5      []\n",
       "3            Waiting to Exhale  31357  tt0114885           6.1      []\n",
       "4  Father of the Bride Part II  11862  tt0113041           5.7      []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies[\"reviews\"] = [[] for _ in range(len(movies))]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[This movie came out when I was three. Now I'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[Throw the dice and take a turn, Jumanji made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>6.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>5.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                original_title     id    imdb_id  vote_average  \\\n",
       "0                    Toy Story    862  tt0114709           7.7   \n",
       "1                      Jumanji   8844  tt0113497           6.9   \n",
       "2             Grumpier Old Men  15602  tt0113228           6.5   \n",
       "3            Waiting to Exhale  31357  tt0114885           6.1   \n",
       "4  Father of the Bride Part II  11862  tt0113041           5.7   \n",
       "\n",
       "                                             reviews  \n",
       "0  [This movie came out when I was three. Now I'm...  \n",
       "1  [Throw the dice and take a turn, Jumanji made ...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "\n",
    "REVIEW_PATTERN = 'https://api.themoviedb.org/3/movie/{movie_id}/reviews?api_key={key}'\n",
    "KEY = '6f2ceb0e0b459afe90f6e854fcd410eb'\n",
    "            \n",
    "def _get_json(url):\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def get_tmdb_reviews():\n",
    "    \"\"\" request reviews with 'id' from TMDB and append them to the reviews column \"\"\"\n",
    "    k=0\n",
    "    for index, row in movies.iterrows():\n",
    "        id = row['id']\n",
    "        r = _get_json(REVIEW_PATTERN.format(key=KEY,movie_id=id))\n",
    "        \n",
    "        if not r:\n",
    "            print(\"request cannot be located\")\n",
    "            continue\n",
    "        \n",
    "        n = r.get('total_results')\n",
    "        \n",
    "        reviews = []\n",
    "        for i in range(n):\n",
    "            k += 1\n",
    "            result = r['results'][i]\n",
    "            review = result.get('content')\n",
    "            reviews.append(review)\n",
    "            #rating = result.get('author_details').get('rating')\n",
    "            \n",
    "        movies.at[index, 'reviews'] = reviews\n",
    "        if not reviews:\n",
    "            movies.at[index, 'reviews'] = float(\"NaN\")\n",
    "        \n",
    "        # SET LIMIT\n",
    "        if index > 20:\n",
    "            print(k)\n",
    "            break\n",
    "\n",
    "    return None\n",
    "\n",
    "get_tmdb_reviews()\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harshikajalan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/harshikajalan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[movie, came, three, im, twenty, seven, goddam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[throw, dice, take, turn, jumanji, made, criti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heat</td>\n",
       "      <td>949</td>\n",
       "      <td>tt0113277</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[dont, live, live, among, remains, dead, peopl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>45325</td>\n",
       "      <td>tt0112302</td>\n",
       "      <td>5.4</td>\n",
       "      <td>[good, enough, doesnt, come, close, disneys, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>710</td>\n",
       "      <td>tt0113189</td>\n",
       "      <td>6.6</td>\n",
       "      <td>[really, solid, entry, series, brosnan, person...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dracula: Dead and Loving It</td>\n",
       "      <td>12110</td>\n",
       "      <td>tt0112896</td>\n",
       "      <td>5.7</td>\n",
       "      <td>[probably, least, favourite, film, mel, brooks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cutthroat Island</td>\n",
       "      <td>1408</td>\n",
       "      <td>tt0112760</td>\n",
       "      <td>5.7</td>\n",
       "      <td>[bad, notoriously, condemned, still, clearly, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Casino</td>\n",
       "      <td>524</td>\n",
       "      <td>tt0112641</td>\n",
       "      <td>7.8</td>\n",
       "      <td>[sharon, stone, robert, de, niro, amazing, rob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Assassins</td>\n",
       "      <td>9691</td>\n",
       "      <td>tt0112401</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Powder</td>\n",
       "      <td>12665</td>\n",
       "      <td>tt0114168</td>\n",
       "      <td>6.3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Leaving Las Vegas</td>\n",
       "      <td>451</td>\n",
       "      <td>tt0113627</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Othello</td>\n",
       "      <td>16420</td>\n",
       "      <td>tt0114057</td>\n",
       "      <td>7.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Now and Then</td>\n",
       "      <td>9263</td>\n",
       "      <td>tt0114011</td>\n",
       "      <td>6.6</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Persuasion</td>\n",
       "      <td>17015</td>\n",
       "      <td>tt0114117</td>\n",
       "      <td>7.4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>La Cité des Enfants Perdus</td>\n",
       "      <td>902</td>\n",
       "      <td>tt0112682</td>\n",
       "      <td>7.6</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>摇啊摇，摇到外婆桥</td>\n",
       "      <td>37557</td>\n",
       "      <td>tt0115012</td>\n",
       "      <td>6.5</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dangerous Minds</td>\n",
       "      <td>9909</td>\n",
       "      <td>tt0112792</td>\n",
       "      <td>6.4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Twelve Monkeys</td>\n",
       "      <td>63</td>\n",
       "      <td>tt0114746</td>\n",
       "      <td>7.4</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Guillaumet, les ailes du courage</td>\n",
       "      <td>78802</td>\n",
       "      <td>tt0114952</td>\n",
       "      <td>6.8</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Babe</td>\n",
       "      <td>9598</td>\n",
       "      <td>tt0112431</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      original_title     id    imdb_id  vote_average  \\\n",
       "0                          Toy Story    862  tt0114709           7.7   \n",
       "1                            Jumanji   8844  tt0113497           6.9   \n",
       "5                               Heat    949  tt0113277           7.7   \n",
       "7                       Tom and Huck  45325  tt0112302           5.4   \n",
       "9                          GoldenEye    710  tt0113189           6.6   \n",
       "11       Dracula: Dead and Loving It  12110  tt0112896           5.7   \n",
       "14                  Cutthroat Island   1408  tt0112760           5.7   \n",
       "15                            Casino    524  tt0112641           7.8   \n",
       "22                         Assassins   9691  tt0112401           6.0   \n",
       "23                            Powder  12665  tt0114168           6.3   \n",
       "24                 Leaving Las Vegas    451  tt0113627           7.1   \n",
       "25                           Othello  16420  tt0114057           7.0   \n",
       "26                      Now and Then   9263  tt0114011           6.6   \n",
       "27                        Persuasion  17015  tt0114117           7.4   \n",
       "28        La Cité des Enfants Perdus    902  tt0112682           7.6   \n",
       "29                         摇啊摇，摇到外婆桥  37557  tt0115012           6.5   \n",
       "30                   Dangerous Minds   9909  tt0112792           6.4   \n",
       "31                    Twelve Monkeys     63  tt0114746           7.4   \n",
       "32  Guillaumet, les ailes du courage  78802  tt0114952           6.8   \n",
       "33                              Babe   9598  tt0112431           6.0   \n",
       "\n",
       "                                              reviews  \n",
       "0   [movie, came, three, im, twenty, seven, goddam...  \n",
       "1   [throw, dice, take, turn, jumanji, made, criti...  \n",
       "5   [dont, live, live, among, remains, dead, peopl...  \n",
       "7   [good, enough, doesnt, come, close, disneys, f...  \n",
       "9   [really, solid, entry, series, brosnan, person...  \n",
       "11  [probably, least, favourite, film, mel, brooks...  \n",
       "14  [bad, notoriously, condemned, still, clearly, ...  \n",
       "15  [sharon, stone, robert, de, niro, amazing, rob...  \n",
       "22                                                 []  \n",
       "23                                                 []  \n",
       "24                                                 []  \n",
       "25                                                 []  \n",
       "26                                                 []  \n",
       "27                                                 []  \n",
       "28                                                 []  \n",
       "29                                                 []  \n",
       "30                                                 []  \n",
       "31                                                 []  \n",
       "32                                                 []  \n",
       "33                                                 []  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string\n",
    "\n",
    "def tokenize(list):\n",
    "    t = []\n",
    "    \n",
    "    for s in list:\n",
    "        tokens = s.split()\n",
    "\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        tokens = [w.translate(table) for w in tokens]\n",
    "        \n",
    "        tokens = [word for word in tokens if word.isalpha()]\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "        \n",
    "        tokens = [word for word in tokens if len(word) > 1]\n",
    "        \n",
    "        t.append(tokens)\n",
    "    \n",
    "    t = [word.lower() for sl in t for word in sl]\n",
    "        \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for w in t:\n",
    "        w = lemmatizer.lemmatize(w)\n",
    "    \n",
    "    # returns a flat list of strings\n",
    "    return t\n",
    "\n",
    "def clean_data():\n",
    "    movies.dropna(subset = [\"reviews\"], inplace=True)\n",
    "    for index, row in movies.iterrows():\n",
    "        review = row['reviews']\n",
    "        movies.at[index, 'reviews'] = tokenize(review)\n",
    "        \n",
    "        # SET LIMIT\n",
    "        if index > 20:\n",
    "            #print(k)\n",
    "            break\n",
    "            \n",
    "    return None\n",
    "\n",
    "clean_data()\n",
    "movies.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"sentences\"] = [\"\" for _ in range(len(movies))]\n",
    "for index, row in movies.iterrows():\n",
    "        words = row['reviews']\n",
    "        movies.at[index, 'sentences'] = ' '.join(words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_length=movies.apply(lambda row: row.apply(len).argmax(), axis=1)\n",
    "def get_max_len():\n",
    "    max_length = movies['reviews'].map(lambda x: len(x)).max()\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# fit a tokenizer\n",
    "def create_tokenizer(list):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(list)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_size(tokenizer):\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def encode_text(tokenizer, lines, length):\n",
    "    encoded = tokenizer.texts_to_sequences(lines)\n",
    "    padded = pad_sequences(encoded, maxlen=length, padding='post')\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[this, movie, came, three, now, im, twenty, se...</td>\n",
       "      <td>this movie came three now im twenty seven godd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>6.9</td>\n",
       "      <td>[throw, dice, take, turn, jumanji, made, criti...</td>\n",
       "      <td>throw dice take turn jumanji made critics gurn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Heat</td>\n",
       "      <td>949</td>\n",
       "      <td>tt0113277</td>\n",
       "      <td>7.7</td>\n",
       "      <td>[you, dont, live, live, among, remains, dead, ...</td>\n",
       "      <td>you dont live live among remains dead people h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tom and Huck</td>\n",
       "      <td>45325</td>\n",
       "      <td>tt0112302</td>\n",
       "      <td>5.4</td>\n",
       "      <td>[good, enough, it, doesnt, come, close, disney...</td>\n",
       "      <td>good enough it doesnt come close disneys film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>710</td>\n",
       "      <td>tt0113189</td>\n",
       "      <td>6.6</td>\n",
       "      <td>[really, solid, entry, series, brosnan, person...</td>\n",
       "      <td>really solid entry series brosnan personally f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_title     id    imdb_id  vote_average  \\\n",
       "0      Toy Story    862  tt0114709           7.7   \n",
       "1        Jumanji   8844  tt0113497           6.9   \n",
       "5           Heat    949  tt0113277           7.7   \n",
       "7   Tom and Huck  45325  tt0112302           5.4   \n",
       "9      GoldenEye    710  tt0113189           6.6   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  [this, movie, came, three, now, im, twenty, se...   \n",
       "1  [throw, dice, take, turn, jumanji, made, criti...   \n",
       "5  [you, dont, live, live, among, remains, dead, ...   \n",
       "7  [good, enough, it, doesnt, come, close, disney...   \n",
       "9  [really, solid, entry, series, brosnan, person...   \n",
       "\n",
       "                                           sentences  \n",
       "0  this movie came three now im twenty seven godd...  \n",
       "1  throw dice take turn jumanji made critics gurn...  \n",
       "5  you dont live live among remains dead people h...  \n",
       "7  good enough it doesnt come close disneys film ...  \n",
       "9  really solid entry series brosnan personally f...  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "[ 206   72  684  685    9  207  686   61   84  687  688    6  208   28\n",
      "  209   26  208  689  690   23  691  210  692  693  211  103   15  100\n",
      "   56  694  207  695  696  212    7   19  213  697  214  199    6  698\n",
      "   18  104  699  187  215  101  700  215  701  702   74  703  704   45\n",
      "  705  706   11  707  216  708  709  710   12   19  120  711   20   10\n",
      "  217  712  713   41  714   38  186  715   53    2    1   90  218   64\n",
      "  716  219  717  718  211   73   24   64  220   19  221  206  154   58\n",
      "   27  222  105  719   29  720  217   35    5  223  103   50  224  225\n",
      "  721   17  226    5  722  106   11  723  724  725  107   30  726  227\n",
      "  228   76  727  728  729  108  730  731   51   31  229   32   62  732\n",
      "  230   63  733  734  735    5  109  736  737  110  738  739   49   43\n",
      "   35  109  740  741  231  232    5  742  743  111  233    3  744  176\n",
      "    2   56  103   50  745  746  747  198  748    7  231   21  749  234\n",
      "  235  184   21  117  750  751  752  753   53  201  754   81  755  224\n",
      "  236  209  756   17  757    3  758  225  221  759  760  761  762  763\n",
      "  764  237  112  765  766  109   21  197  113  232    4   22  767   32\n",
      "  768  769    5  770   30  771   14  772  773  774   75  775  238  776\n",
      "  132  777  104  778  779  780   34  159  135  781   48   29    1  114\n",
      "  782  783  784  785   27   42  786  787  788  214  789  790  239  791\n",
      "   80  792  156  106   30  793   29   95   10  175  794  795  796  240\n",
      "  797  798  799  800  801  802  803  804   23  805  806    4    1  807\n",
      "  808  809  114  810  811  812  241  234  235   52   31  813  814  242\n",
      "  815   52  816  243  817  818  243  223  114  105  819   52  820  177\n",
      "  821  822  147  165  823   51   31   69  824   28   76   40  825  826\n",
      "  827   37   70  106   11  107   30  229   32  828  829  830  831  832\n",
      "  244  133  833   60  163  134  245  164  834  835    1  122  136  836\n",
      "  837  838   80  839  840  841  123  246  842  843  844  112  845  846\n",
      "  847  848  849    1  850  851  852  153  853  854  855  242  856  857\n",
      "   51   31  110  247  148  149  238  858  859   10  236  860  240  861\n",
      "   50  862  248  249  863    1  864  218  865  866  867  868   91  869\n",
      "  870  871  872  873  248  874  213    3    5    3  875  876   16  204\n",
      "  877   16  878   11  226    5  879  880   61  881  882  108  188  227\n",
      "  883  884  228   54  137   34  885  886   75    2  887  888  230  889\n",
      "   32    4  139  890   28   46  891  892   47  893  894  895  896  897\n",
      "  898  899  900  113   82    6  901  902   29   94   27  111  250  903\n",
      "  195  111  904  905  906  907  233  241   52  908  909  125  910  911\n",
      "   86  251   87  912  913  914  915   81  245    7  916    6  917  918\n",
      "  919  252  920  921  922  923  924  250   49   49  925  180  926  155\n",
      "  927  182  928  929  930  931  110   96  932  933  934  935  936    2\n",
      "   15   94  145   92   50  937    5    7    1   20   29  938  247  939\n",
      "  940  101  941  222  105  942  943  220    3  944   91  205  157   14\n",
      "  945    3  946  947  237  948  181  251  949    6  252  185  950  951\n",
      "  952  953   51   31  150   41  253  254  954   95   54  955  956  957\n",
      "  958  959   11  960  104   28  961  962   93  963  212  964  965  966\n",
      "  967  968   21  969  255  970  971  178  972  210   20  171  193    7\n",
      "  973  974  975    4   44  976  977   63   28  174  255  978  979  980\n",
      "   11  981   82   26   43   48  244  982  200   18  983  162  984  985\n",
      "  986  216   17  115  107   30  987  988   11  989  169  990  991  992\n",
      "  993  994  249   96   32  100  995  253  202  246   14   99  113   48\n",
      "  996  997  128   21  998  999  144 1000 1001  254   41 1002 1003 1004\n",
      " 1005  108    1 1006 1007 1008   18  219    5    3 1009 1010]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "\n",
    "test = movies['sentences'].tolist()\n",
    "tokenizer = create_tokenizer(test)\n",
    "print(get_vocab_size(tokenizer))\n",
    "\n",
    "# encode data\n",
    "test_encoded = encode_text(tokenizer, test, get_max_len())\n",
    "print(test_encoded.shape)\n",
    "from keras.utils.vis_utils import plot_model\n",
    "print(test_encoded[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 712)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 712)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 712)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_10 (Embedding)        (None, 712, 100)     102300      input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_11 (Embedding)        (None, 712, 100)     102300      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 712, 100)     102300      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 709, 32)      12832       embedding_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 707, 32)      19232       embedding_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 705, 32)      25632       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 709, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 707, 32)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 705, 32)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 354, 32)      0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 353, 32)      0           dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 352, 32)      0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 11328)        0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 11296)        0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 11264)        0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 33888)        0           flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           338890      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            11          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 703,497\n",
      "Trainable params: 703,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "def custom_model(length, vocab_size):\n",
    "    # channel 1\n",
    "    inputs1 = Input(shape=(length,))\n",
    "    embedding1 = Embedding(vocab_size, 100)(inputs1)\n",
    "    conv1 = Conv1D(filters=32, kernel_size=4, activation='relu')(embedding1)\n",
    "    drop1 = Dropout(0.5)(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(drop1)\n",
    "    flat1 = Flatten()(pool1)\n",
    "    \n",
    "    # channel 2\n",
    "    inputs2 = Input(shape=(length,))\n",
    "    embedding2 = Embedding(vocab_size, 100)(inputs2)\n",
    "    conv2 = Conv1D(filters=32, kernel_size=6, activation='relu')(embedding2)\n",
    "    drop2 = Dropout(0.5)(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(drop2)\n",
    "    flat2 = Flatten()(pool2)\n",
    "    \n",
    "    # channel 3\n",
    "    inputs3 = Input(shape=(length,))\n",
    "    embedding3 = Embedding(vocab_size, 100)(inputs3)\n",
    "    conv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\n",
    "    drop3 = Dropout(0.5)(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(drop3)\n",
    "    flat3 = Flatten()(pool3)\n",
    "    \n",
    "    # merge\n",
    "    merged = concatenate([flat1, flat2, flat3])\n",
    "    \n",
    "    # interpretation\n",
    "    dense1 = Dense(10, activation='relu')(merged)\n",
    "    outputs = Dense(1, activation='sigmoid')(dense1)\n",
    "    model = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n",
    "    \n",
    "    # compile\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # summarize\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = custom_model(get_max_len(), get_vocab_size(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
