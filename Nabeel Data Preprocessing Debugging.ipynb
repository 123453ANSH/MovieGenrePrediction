{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import nltk\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#come back and get rid of functions not using\n",
    "filename = \"ImageData\"\n",
    "filenameTwo = \"Genres\"\n",
    "fileNameThree =  \"xTrain\"\n",
    "fileNameFour =  \"xTest\"\n",
    "fileNameFive =  \"yTrain\"\n",
    "fileNameSix =  \"yTest\"\n",
    "fileNameSeven = \"filePathIndex\"\n",
    "\n",
    "def loadTrain(): \n",
    "    filehandler = open(fileNameThree, 'rb') \n",
    "    xTrain = np.load(filehandler, allow_pickle=True) #pickle.load(filehandler)\n",
    "    filehandlerTwo = open(fileNameFive, 'rb')\n",
    "    yTrain = np.load(filehandlerTwo, allow_pickle=True)\n",
    "    return xTrain, yTrain\n",
    "\n",
    "def loadTest(): \n",
    "    filehandler = open(fileNameFour, 'rb') \n",
    "    xTest = np.load(filehandler, allow_pickle=True) #pickle.load(filehandler)\n",
    "    filehandlerTwo = open(fileNameSix, 'rb') \n",
    "    yTest = np.load(filehandlerTwo, allow_pickle=True) #pickle.load(filehandler)\n",
    "    return xTest, yTest\n",
    "\n",
    "def saveImages(imageList, genres, pathOne, pathTwo): \n",
    "    filehandler = open(pathOne, 'wb')\n",
    "    np.save(filehandler, imageList)\n",
    "    filehandlerTwo = open(pathTwo, 'wb')\n",
    "    np.save(filehandlerTwo, genres)\n",
    "    #pickle.dump(imageList, filehandler)\n",
    "    \n",
    "def saveDataFrame(dataFrame, name):\n",
    "    dataFrame.to_json(name)\n",
    "\n",
    "def loadData(path): \n",
    "    filehandler = open(path, 'rb') \n",
    "    files = np.load(filehandler, allow_pickle=True) #pickle.load(filehandler)\n",
    "    return files\n",
    "\n",
    "def saveData(data, path): \n",
    "    filehandler = open(path, 'wb')\n",
    "    np.save(filehandler, data)\n",
    "        \n",
    "def loadImages(): \n",
    "    filehandler = open(filename, 'rb') \n",
    "    files = np.load(filehandler, allow_pickle=True) #pickle.load(filehandler)\n",
    "    return files\n",
    "\n",
    "def loadGenres(): \n",
    "    filehandlerTwo = open(filenameTwo, 'rb')\n",
    "    genres = np.load(filehandlerTwo, allow_pickle=True)\n",
    "    return genres\n",
    "\n",
    "def load(filePath): \n",
    "    loader = csv\n",
    "\n",
    "def tempSave(genres): \n",
    "    genres.to_csv(path_or_buf = filenameTwo)\n",
    "    \n",
    "def saveTesting(csv, path): \n",
    "    csv.to_csv(path_or_buf = path)\n",
    "    \n",
    "def fromCsv(path): \n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def dataTypes(data): \n",
    "    print(type(data))\n",
    "    print(type(data[0]))\n",
    "    print(type(data[0][0]))\n",
    "    print(type(data[0][0][0]))\n",
    "    print(type(data[0][0][0][0]))\n",
    "    try:\n",
    "        print(type(data[0][0][0][0][0]))\n",
    "    except: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testStrings(dataFrame): \n",
    "    \"\"\"\n",
    "    tests to see if there are any strings in any image array\n",
    "    \"\"\"\n",
    "    errorVectors = []\n",
    "    data = dataFrame['imageArrays']\n",
    "    for i in range(len(data)):\n",
    "        array = data.iloc[i]\n",
    "        for j in range(len(array)): \n",
    "            for k in range(len(array[j])): \n",
    "                lenLists = len(array[j][k])\n",
    "                for l in range(lenLists): \n",
    "                    if type(array[j][k][l]) != dataType:\n",
    "                        errorVectors.append(array[j][k])\n",
    "                        break\n",
    "                if (data.iloc[i] == []): \n",
    "                    break\n",
    "            if (data.iloc[i] == []): \n",
    "                break\n",
    "        if (data.iloc[i] == []): \n",
    "            continue\n",
    "    return errorVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToNumpy(movies):\n",
    "    for i in range(len(movies['imageArrays'])):\n",
    "        for j in range(len(movies['imageArrays'].iloc[i])): \n",
    "            for k in range(len(movies['imageArrays'].iloc[i][j])): \n",
    "                movies['imageArrays'].iloc[i][j][k] = np.array(movies['imageArrays'].iloc[i][j][k])\n",
    "            movies['imageArrays'].iloc[i][j] = np.array(movies['imageArrays'].iloc[i][j])\n",
    "        movies['imageArrays'].iloc[i] = np.array(movies['imageArrays'].iloc[i])\n",
    "\n",
    "def convertToTensor(movies):\n",
    "    for i in range(len(movies['imageArrays'])):\n",
    "        for j in range(len(movies['imageArrays'].iloc[i])): \n",
    "            for k in range(len(movies['imageArrays'].iloc[i][j])): \n",
    "                movies['imageArrays'].iloc[i][j][k] = torch.Tensor(movies['imageArrays'].iloc[i][j][k], dtype='torch.float32')\n",
    "            movies['imageArrays'].iloc[i][j] = torch.Tensor(movies['imageArrays'].iloc[i][j])\n",
    "        movies['imageArrays'].iloc[i] = torch.Tensor(movies['imageArrays'].iloc[i])\n",
    "        \n",
    "def convertToFloat(movies):\n",
    "    for i in range(len(movies['imageArrays'])):\n",
    "        for j in range(len(movies['imageArrays'].iloc[i])): \n",
    "            for k in range(len(movies['imageArrays'].iloc[i][j])): \n",
    "                for l in range(len(movies['imageArrays'].iloc[i][j][k])):\n",
    "                    movies['imageArrays'].iloc[i][j][k][l] = float(movies['imageArrays'].iloc[i][j][k][l])\n",
    "           \n",
    "       \n",
    "def convertToList(movies):\n",
    "    for i in range(len(movies['imageArrays'])):\n",
    "        for j in range(len(movies['imageArrays'].iloc[i])): \n",
    "            for k in range(len(movies['imageArrays'].iloc[i][j])): \n",
    "                movies['imageArrays'].iloc[i][j][k].tolist()\n",
    "                #print(movies['imageArrays'].iloc[i][j][k])\n",
    "                #movies['imageArrays'].iloc[i][j][k] = float(movies['imageArrays'].iloc[i][j][k]) #, dtype='torch.float32')\n",
    "            movies['imageArrays'].iloc[i][j].tolist() #movies['imageArrays'].iloc[i][j] = \n",
    "        movies['imageArrays'].tolist() #movies['imageArrays'].iloc[i] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalImageArrayIter(imageArrays, function): \n",
    "    data = imageArrays['imageArrays']\n",
    "    for i in range(len(data)):\n",
    "        array = data.iloc[i]\n",
    "        for j in range(len(array)): \n",
    "            for k in range(len(array[j])): \n",
    "                lenLists = len(array[j][k])\n",
    "                print(array[j][k], type(array[j][k]))\n",
    "                for l in range(lenLists): \n",
    "                    array[j][k][l] = function(array[j][k][l]) \n",
    "                    #reassignment is not working\n",
    "                    print(function(array[j][k][l]), type(function(array[j][k][l])))\n",
    "                    print(array[j][k][l], type(array[j][k][l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_json(\"X_train\")\n",
    "X_test = pd.read_json(\"X_test\")\n",
    "y_train = pd.read_json(\"y_train\")\n",
    "y_test = pd.read_json(\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "XImages_train = X_train['imageArrays'].values\n",
    "XImages_train = list(XImages_train)\n",
    "#XImages_train = XImages_train.to_numpy()\n",
    "#XImages_train.astype(np.float32)\n",
    "yImages_train = y_train.to_numpy()\n",
    "tensor_y = torch.Tensor(yImages_train) # transform to torch tensor\n",
    "tensor_x = torch.Tensor(XImages_train) #from_numpy\n",
    "#torch.as_tensor(XImages_train)\n",
    "trainDataset = TensorDataset(tensor_y,tensor_x) # create your datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
